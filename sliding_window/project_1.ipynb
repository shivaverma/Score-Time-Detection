{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training data: 60000\n",
      "total testing data: 10000\n",
      "dimensions of image: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"total training data: %d\" %len(x_train))\n",
    "print(\"total testing data: %d\" %len(x_test))\n",
    "print(\"dimensions of image:\",(x_train[0]).shape)\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_model():\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "    model.save(\"mnist.model\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_and_save_model() \n",
    "\n",
    "model = tf.keras.models.load_model(\"mnist.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 46us/step\n",
      "\n",
      "val loss: 0.08651540782800876 \n",
      "val_acc: 0.9754\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(\"\\nval loss:\", val_loss, \"\\nval_acc:\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_digit(image_path):\n",
    "\n",
    "    image = [cv2.imread(image_path, cv2.IMREAD_GRAYSCALE,),]\n",
    "    plt.imshow(image[0])\n",
    "    print(\"image shape:\",image[0].shape)\n",
    "\n",
    "    image[0] = cv2.resize(image[0], (28, 28)) \n",
    "    image[0] = image[0]/255\n",
    "    image[0] = 1 - image[0]\n",
    "    plt.imshow(image[0])\n",
    "\n",
    "    predict = model.predict([image])\n",
    "    # print(predict)\n",
    "    print(\"Predicted Number:\", np.argmax(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (217, 218)\n",
      "Predicted Number: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADhFJREFUeJzt3X+MHPV5x/HPc4cxYBOXOx8n1xw+IBciSoKJLlYlaEuVQBxIa0gjJ1YbuRKKiRLUpkklkKuq/FFFqGqIkNpGOoKFiRISRHCwFDdArChuIpJyEBdsDDGlDvb57DvbAfwLnX1++scN6AI3313vzuzs+Xm/pNPtzjOz82h8H8/sfnf3a+4uAPF0VN0AgGoQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQZ3Vyp0t7Or0/r45rdwlEMqu3Sd04NCk1bNuU+E3s+WS7pXUKemb7n53av3+vjn678f7mtklgIRlH9td97oNX/abWaekf5f0cUlXSFplZlc0+ngAWquZ5/zLJL3s7q+4+4Sk70paUUxbAMrWTPgXS5p+jbEnW/Y7zGyNmQ2b2fD4wckmdgegSKW/2u/uQ+4+6O6DPd2dZe8OQJ2aCf+IpOmv3l2ULQMwCzQT/qclDZjZJWZ2tqTPSNpYTFsAytbwUJ+7nzSz2yU9rqmhvnXuvr2wzgCUqqlxfnffJGlTQb0AaCHe3gsERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQTc3Sa2a7JB2WNCnppLsPFtFUNMdOTSTrn/z1Lcl6h3lu7av9G5LbLp07N1k/U53wyWT9L//vhmT9UxcOJ+sr579+2j21WlPhz/ypux8o4HEAtBCX/UBQzYbfJT1hZs+Y2ZoiGgLQGs1e9l/r7iNmdqGkJ83sRXffMn2F7D+FNZJ08eIinmUAKEJTZ353H8l+j0naIGnZDOsMufuguw/2dHc2szsABWo4/GY2z8zOf+u2pBskbSuqMQDlauY6vFfSBjN763G+4+4/KqQrAKVrOPzu/oqkqwrs5YxVa0x5+fZPJ+uvHT8nWe+edyy3FnUcX0of9/c9flty24H7TiTr9z91MFlfuXdrst4OGOoDgiL8QFCEHwiK8ANBEX4gKMIPBMX7bQtQayjvL16+KVk/OjEnWX//wrFk/eFLNyfrUf3ZS3+eW+t4Lf2nf9ZX9ybrmy5v/6G8WjjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQjPMXYMPRrmT98ERzH6t9oP8/a6xxdlOPP1u9evJIsv7Si4tzaz2Xpz+S+8jAD2rsffYfc878QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/x1OnLqzdzad0Y/1tRjr+z/VbJ+XsfsH1NuxNjk0WT9+qe+0PBjX7Uw/Xn9CMecMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBFVznN/M1kn6hKQxd78yW9Yl6XuS+iXtkrTS3X9bXpvV+8ATt+fWzltwPLlt3wWvJet/3/VSjb3H/D/6n/dfl6yfOJ6e7+ADf/Bqbu2+vp830tIZpZ6/qgckLX/HsjslbXb3AUmbs/sAZpGa4Xf3LZIOvWPxCknrs9vrJd1ccF8AStbo9WSvu49mt/dJ6i2oHwAt0vSTSXd3SZ5XN7M1ZjZsZsPjB9Nz2gFonUbDv9/MFklS9jt3Jkl3H3L3QXcf7OnubHB3AIrWaPg3Slqd3V4t6bFi2gHQKjXDb2YPSXpK0uVmtsfMbpV0t6TrzWynpI9m9wHMIjXH+d19VU7pIwX3csY6p/Nkst5pZ+44/qSfyq19YeSa5Lb/9eplTe1748CPmtr+THfm/tUBSCL8QFCEHwiK8ANBEX4gKMIPBMVXd7fA6xPnJOvLX7wpWe+w3HdPS5I+2vNibm3H0UXJbf9oQfrjxB+cO5KsP/L6YLK+7fXfz63tPfKe5LYTE+k/z/cvGU3WkcaZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpy/Tp//8E9zaxt2X9XUY48fnZesT5xM/zP92wvX59Yu/mH+R2ol6Sd/NZCsv29R7pc0lW7B+ceS9YcHHq3xCOn3V0THmR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKcv053dO/MrX25K//z9JK0fSL91d337Msfp5ekX+27KFn3c/OnQXvj84eT236o60Cyfsm8g8n6P/b8IllfufOTyXpK7/wjyfr8Dsbxm8GZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjnOb2brJH1C0pi7X5ktu0vS5ySNZ6utdfdNZTXZ7uZYZ7K+dG66/uCSLekdLDndjlrn2Kn0+eOsjvzvE+g6N/15/UcGflBj72fXqCOlnjP/A5KWz7D86+6+NPsJG3xgtqoZfnffIulQC3oB0ELNPOe/3cyeM7N1ZnZBYR0BaIlGw/8NSZdJWippVNLX8lY0szVmNmxmw+MH89+DDqC1Ggq/u+9390l3PyXpPknLEusOufuguw/2dKdf+ALQOg2F38ymT/16i6RtxbQDoFXqGep7SNJ1khaa2R5J/yTpOjNbKskl7ZJ0W4k9AihBzfC7+6oZFt9fQi+Yhf5u758k6ycT7wP48sVPJLc9r4Nx/DLxDj8gKMIPBEX4gaAIPxAU4QeCIvxAUHx1N5J+eCz99di7j6Y/1nHKLbe2dO5rNfaenroczeHMDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc6PpI2Hrm5q+wvPzZ8i/MJOxvGrxJkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinB9JzXxeX5L+oy/19dzp7wpAuTjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQNcf5zaxP0oOSeiW5pCF3v9fMuiR9T1K/pF2SVrr7b8trFWX4m70fLvXx53cwlt+u6jnzn5T0FXe/QtIfSvqimV0h6U5Jm919QNLm7D6AWaJm+N191N2fzW4flrRD0mJJKyStz1ZbL+nmspoEULzTes5vZv2Srpb0S0m97j6alfZp6mkBgFmi7vCb2XxJ35f0JXd/Y3rN3V1TrwfMtN0aMxs2s+Hxg5NNNQugOHWF38zmaCr433b3R7PF+81sUVZfJGlspm3dfcjdB919sKe7s4ieARSgZvjNzCTdL2mHu98zrbRR0urs9mpJjxXfHoCy1POR3mskfVbS82a2NVu2VtLdkh42s1sl/UbSynJaRJmeOdCXrC+Y+2ay/t7zDzS870k/lawf94lknWHE5tQMv7v/TFLeh7Y/Umw7AFqFd/gBQRF+ICjCDwRF+IGgCD8QFOEHguKru1Gqh48syK2t23NtctsOm/Ed42/bdPmmhnrCFM78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/xoyitHumvUr8mt/d7c48ltv7mk1jg+n+dvBmd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf7g1r43PZa+fl/+OL0kffA9I8n6Hd3bc2tzrNYMTozjl4kzPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVXOc38z6JD0oqVeSSxpy93vN7C5Jn5M0nq261t35IvVZ5qbz3kzXL93c5B5qjeWjKvW8yeekpK+4+7Nmdr6kZ8zsyaz2dXf/1/LaA1CWmuF391FJo9ntw2a2Q9LishsDUK7Tes5vZv2Srpb0y2zR7Wb2nJmtM7MLcrZZY2bDZjY8fnCyqWYBFKfu8JvZfEnfl/Qld39D0jckXSZpqaauDL4203buPuTug+4+2NPN8z+gXdQVfjObo6ngf9vdH5Ukd9/v7pPufkrSfZKWldcmgKLVDL+ZmaT7Je1w93umLV80bbVbJG0rvj0AZann1f5rJH1W0vNmtjVbtlbSKjNbqqnhv12SbiulQwClqOfV/p9JshlKjOkDsxjv8AOCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRl7t66nZmNS/rNtEULJR1oWQOnp117a9e+JHprVJG9LXH3nnpWbGn437Vzs2F3H6ysgYR27a1d+5LorVFV9cZlPxAU4QeCqjr8QxXvP6Vde2vXviR6a1QlvVX6nB9Adao+8wOoSCXhN7PlZvaSmb1sZndW0UMeM9tlZs+b2VYzG664l3VmNmZm26Yt6zKzJ81sZ/Z7xmnSKurtLjMbyY7dVjO7saLe+szsJ2b2gpltN7O/zZZXeuwSfVVy3Fp+2W9mnZJ+Lel6SXskPS1plbu/0NJGcpjZLkmD7l75mLCZ/bGkI5IedPcrs2X/IumQu9+d/cd5gbvf0Sa93SXpSNUzN2cTyiyaPrO0pJsl/bUqPHaJvlaqguNWxZl/maSX3f0Vd5+Q9F1JKyroo+25+xZJh96xeIWk9dnt9Zr642m5nN7agruPuvuz2e3Dkt6aWbrSY5foqxJVhH+xpN3T7u9Re0357ZKeMLNnzGxN1c3MoDebNl2S9knqrbKZGdScubmV3jGzdNscu0ZmvC4aL/i927Xu/iFJH5f0xezyti351HO2dhquqWvm5laZYWbpt1V57Bqd8bpoVYR/RFLftPsXZcvagruPZL/HJG1Q+80+vP+tSVKz32MV9/O2dpq5eaaZpdUGx66dZryuIvxPSxows0vM7GxJn5G0sYI+3sXM5mUvxMjM5km6Qe03+/BGSauz26slPVZhL7+jXWZuzptZWhUfu7ab8drdW/4j6UZNveL/v5L+oYoecvq6VNL/ZD/bq+5N0kOaugw8oanXRm6V1C1ps6Sdkn4sqauNevuWpOclPaepoC2qqLdrNXVJ/5ykrdnPjVUfu0RflRw33uEHBMULfkBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgvp/aBg6YyXNsRkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_digit(\"digit/four.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras' has no attribute 'train_datagen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d0cd544dc48b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train = tf.keras.train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"digit/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     target_size=(28, 28))\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.keras' has no attribute 'train_datagen'"
     ]
    }
   ],
   "source": [
    "train = tf.keras.train_datagen.flow_from_directory(\n",
    "    \"digit/\",\n",
    "    target_size=(28, 28))\n",
    "\n",
    "#print(image)\n",
    "#y = [2]\n",
    "\n",
    "#model.fit(image[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
